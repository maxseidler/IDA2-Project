{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:46:53.532427Z",
     "start_time": "2018-03-13T23:46:53.517611Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:46:55.076374Z",
     "start_time": "2018-03-13T23:46:55.056619Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(mode):\n",
    "    \"\"\" divides data into images and labels\n",
    "        Min-Max scales images\n",
    "    Params:\n",
    "        mode : String (either \"padded\" or \"resized\")\n",
    "    Returns:\n",
    "        scaled_X : array with images\n",
    "        y : array with corresponding labels\n",
    "        (0 for non-IDC, 1 for IDC)\n",
    "    \"\"\"\n",
    "    patches = glob.glob('./' + mode + '/*.png', recursive=True)\n",
    "    class0 = []\n",
    "    class1 = []\n",
    "    for name in glob.glob('./' + mode + '/*class0.png', recursive=True):\n",
    "        class0.append(name)\n",
    "    for name in glob.glob('./' + mode + '/*class1.png', recursive=True):\n",
    "        class1.append(name)\n",
    "    X = []\n",
    "    y = []\n",
    "    for img_name in patches:\n",
    "        image = cv2.imread(img_name)\n",
    "        X.append(image)\n",
    "        y.append(0) if img_name in class0 else y.append(1)\n",
    "    scaled_X = np.array(X)/255.0\n",
    "    return scaled_X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:46:56.757048Z",
     "start_time": "2018-03-13T23:46:56.688221Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_CNN():\n",
    "    input_shape = (50, 50, 3)\n",
    "    num_classes = 2\n",
    "    reg = 0.0001\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), padding='same', kernel_initializer='he_normal', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (5, 5), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=l2(reg)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:46:59.352379Z",
     "start_time": "2018-03-13T23:46:58.470857Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_pad = create_CNN()\n",
    "cnn_pad.summary()\n",
    "plot_model(cnn_pad, to_file='simple_cnn_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:47:16.861169Z",
     "start_time": "2018-03-13T23:47:00.639681Z"
    }
   },
   "outputs": [],
   "source": [
    "X_pad, y = prepare_data(\"padded\")\n",
    "\n",
    "print(X_pad.shape)\n",
    "print(y.count(1))\n",
    "print(y.count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T23:48:23.713864Z",
     "start_time": "2018-03-13T23:48:23.692085Z"
    }
   },
   "outputs": [],
   "source": [
    "def balance(X, y):\n",
    "    \"\"\" Function for getting perfectly balanced data set (50/50)\n",
    "        Takes as many negative examples, as there are positive ones\n",
    "        DON'T USE IT IF YOUR DATASET IS OK\n",
    "    \"\"\"\n",
    "    X0 = []\n",
    "    X1 = []\n",
    "    for i in range(0, len(y)):\n",
    "        X1.append(X[i]) if y[i] == 1 else X0.append(X[i]) \n",
    "        X0 = np.array(X0)\n",
    "        X1 = np.array(X1)\n",
    "    \n",
    "    random.shuffle(X0)\n",
    "    balanced_X0 = X0[:len(X1)] \n",
    "    X_balanced = np.concatenate((balanced_X0, X1))\n",
    "\n",
    "    a = [0] * len(balanced_X0) \n",
    "    b = [1] * len(X1)\n",
    "    y_balanced = a + b\n",
    "\n",
    "    return X_balanced, y_balanced\n",
    "    \n",
    "#X_pad, y = balance(X_pad, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T03:17:51.810399Z",
     "start_time": "2018-03-13T23:48:28.538350Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tune, X_test, y_train_tune, y_test = train_test_split(X_pad, y, test_size=0.1, random_state=42)\n",
    "\n",
    "y_train_tune_onehot = np_utils.to_categorical(y_train_tune, 2)\n",
    "y_test_onehot = np_utils.to_categorical(y_test, 2)\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()), histogram_freq=1, batch_size=batch_size, \n",
    "                          write_grads=True, write_images=True)\n",
    "\n",
    "fit_history = cnn_pad.fit(X_train_tune, y_train_tune_onehot,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True, \n",
    "                      verbose=1, validation_split=0.1, callbacks=[early_stopping, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T03:17:52.164682Z",
     "start_time": "2018-03-14T03:17:51.814608Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \"\"\" Util function for plotting model's accuracy and loss\n",
    "        Actually it can be deleted since all this info is in Tensorboard\n",
    "        Go for it \n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].plot(history.history['acc'])\n",
    "    axs[0].plot(history.history['val_acc'])\n",
    "    axs[0].set_xticks(np.arange(1, len(history.history['acc'])+1))\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].plot(history.history['loss'])\n",
    "    axs[1].plot(history.history['val_loss'])\n",
    "    axs[1].set_xticks(np.arange(1, len(history.history['loss'])+1))\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "#plot_history(fit_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T22:43:57.463715Z",
     "start_time": "2018-03-13T22:43:57.457678Z"
    }
   },
   "outputs": [],
   "source": [
    "#score_pad = cnn_pad.evaluate(X_test, y_test_onehot, verbose=0)\n",
    "#print('Test loss:', score_pad[0])\n",
    "#print('Test accuracy:', score_pad[1])\n",
    "\n",
    "#plt.plot(fit_history.history['loss'])\n",
    "#plt.xlabel('Epoch')\n",
    "#plt.ylabel('Loss')\n",
    "#plt.title('Simple CNN with padded imgs')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
